# ğŸ›¡ï¸ Adversarial Patch Papers Collection

> ğŸ“š **A comprehensive collection of research papers on backdoor defenses in machine learning.**  
> ğŸ“ **Maintained by**: Dr. [Jingyu Wang] | [School of Computer Science, Chongqing University of Posts and Telecommunications] | [d230201034@stu.cqupt.edu.cn]

## ğŸ“– About This Repository

This repository serves as a curated collection of academic papers focusing on **adversarial patch** in machine learning. Our goal is to provide researchers, practitioners, and students with a comprehensive overview of the current state-of-the-art in this critical security domain.


### ğŸ¯ **Repository Purpose:**
- ğŸ† **Quality Focus**: Emphasis on high-impact venues. [CCF-Rankings](https://www.ccf.org.cn/en/About_CCF/Media_Center/) now marked with different colors(![arXiv](https://img.shields.io/badge/CCF_A-dc3545) ![Static Badge](https://img.shields.io/badge/CCF_B-ffc107) ![Static Badge](https://img.shields.io/badge/CCF_C-28a745) ![Static Badge](https://img.shields.io/badge/CCF_None-6c757d))
- ğŸ”„ **Regular Updates**: Continuously updated with latest research developments
- ğŸŒ **Easy Access**: Direct links to papers, code repositories, and supplementary materials

### ğŸ“Š **Each paper includes the following evaluation metrics (out of 5 stars):**
- **ğŸ’¡ Motivation**: How well-motivated and significant is the research problem? â­â­â­â­â­ (5/5)
- **ğŸ”§ Method**: How novel and technically sound is the proposed approach? â­â­â­â­â­ (5/5)

<h2 id="awesome-papers"> ğŸ‘‘ Awesome Papers List â€œATTACKâ€ </h2>

<h3 id="attacks"> 2023 </h3>

* **[2023]** **[T-SEA: Transfer-based Self-Ensemble Attack on Object Detection](https://openaccess.thecvf.com/content/CVPR2023/html/Huang_T-SEA_Transfer-Based_Self-Ensemble_Attack_on_Object_Detection_CVPR_2023_paper.html)** ![Static Badge](https://img.shields.io/badge/CVPR'23-6c757d) [![GitHub stars](https://img.shields.io/github/stars/VDIGPKU/T-SEA?style=social)]([[https://github.com/VDIGPKU/T-SEA](https://github.com/VDIGPKU/T-SEA)]) 
  * Hao Huang, Ziyan Chen, Huanran Chen, Yongtao Wang, Kevin Zhang
  * **ğŸ“ Summary**: The method integrates data augmentation and model enhancement, allowing attacks on various black-box models through the access of a single white-box model.
  * **ğŸ’¡ Motivation**: â­â­â­â­â­ (5/5) - It solves the key challenge of poor transferability of adversarial patches caused by the inability to access black-box models in real-world scenarios.
  * **ğŸ”§ Method**: â­â­â­â­â­ (5/5) - This method draws an analogy between the training process of adversarial patches and that of neural networks, offering a simple yet effective approach.
