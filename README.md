# 🛡️ Adversarial Patch Papers Collection

> 📚 **A comprehensive collection of research papers on backdoor defenses in machine learning.**  
> 🎓 **Maintained by**: Dr. [Jingyu Wang] | [School of Computer Science, Chongqing University of Posts and Telecommunications] | [d230201034@stu.cqupt.edu.cn]

## 📖 About This Repository

This repository serves as a curated collection of academic papers focusing on **adversarial patch** in machine learning. Our goal is to provide researchers, practitioners, and students with a comprehensive overview of the current state-of-the-art in this critical security domain.


### 🎯 **Repository Purpose:**
- 🏆 **Quality Focus**: Emphasis on high-impact venues. [CCF-Rankings](https://www.ccf.org.cn/en/About_CCF/Media_Center/) now marked with different colors(![arXiv](https://img.shields.io/badge/CCF_A-dc3545) ![Static Badge](https://img.shields.io/badge/CCF_B-ffc107) ![Static Badge](https://img.shields.io/badge/CCF_C-28a745) ![Static Badge](https://img.shields.io/badge/CCF_None-6c757d))
- 🔄 **Regular Updates**: Continuously updated with latest research developments
- 🌐 **Easy Access**: Direct links to papers, code repositories, and supplementary materials

### 📊 **Each paper includes the following evaluation metrics (out of 5 stars):**
- **💡 Motivation**: How well-motivated and significant is the research problem? ⭐⭐⭐⭐⭐ (5/5)
- **🔧 Method**: How novel and technically sound is the proposed approach? ⭐⭐⭐⭐⭐ (5/5)

<h2 id="awesome-papers"> 👑 Awesome Papers List “ATTACK” </h2>

<h3 id="attacks"> 2023 </h3>

* **[2023]** **[T-SEA: Transfer-based Self-Ensemble Attack on Object Detection](https://openaccess.thecvf.com/content/CVPR2023/html/Huang_T-SEA_Transfer-Based_Self-Ensemble_Attack_on_Object_Detection_CVPR_2023_paper.html)** ![Static Badge](https://img.shields.io/badge/CVPR'23-6c757d) [![GitHub stars](https://img.shields.io/github/stars/VDIGPKU/T-SEA?style=social)]([[https://github.com/VDIGPKU/T-SEA](https://github.com/VDIGPKU/T-SEA)]) 
  * Hao Huang, Ziyan Chen, Huanran Chen, Yongtao Wang, Kevin Zhang
  * **📝 Summary**: The method integrates data augmentation and model enhancement, allowing attacks on various black-box models through the access of a single white-box model.
  * **💡 Motivation**: ⭐⭐⭐⭐⭐ (5/5) - It solves the key challenge of poor transferability of adversarial patches caused by the inability to access black-box models in real-world scenarios.
  * **🔧 Method**: ⭐⭐⭐⭐⭐ (5/5) - This method draws an analogy between the training process of adversarial patches and that of neural networks, offering a simple yet effective approach.
